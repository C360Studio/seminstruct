# Shimmy build with custom GGUF model baked in
#
# For default Qwen2.5-0.5B, use the pre-built image instead:
#   docker pull ghcr.io/c360studio/semshimmy:latest
#
# Use this Dockerfile to bake in a different model:
#   MODEL_REPO=TheBloke/Mistral-7B-Instruct-v0.2-GGUF \
#   MODEL_FILE=mistral-7b-instruct-v0.2.Q4_K_M.gguf \
#   docker build -f Dockerfile.shimmy -t shimmy:custom .

FROM rust:1.85-slim AS builder

RUN apt-get update && apt-get install -y \
    pkg-config \
    libssl-dev \
    build-essential \
    git \
    clang \
    libclang-dev \
    cmake \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Clone shimmy from source
RUN git clone --depth 1 https://github.com/michael-a-kuykendall/shimmy.git .

# Build the application (skip benches that cause build issues)
RUN cargo build --release --features huggingface --lib --bins

# Model download stage - downloads GGUF at build time
FROM python:3.11-slim AS model-downloader

RUN pip install --no-cache-dir huggingface-hub

WORKDIR /models

# Build args for model selection
# Default: Qwen2.5-0.5B Q4_K_M (~491MB) - ideal for edge devices and CI
# Override with Mistral-7B variants for more resources (~4-6GB)
ARG MODEL_REPO=Qwen/Qwen2.5-0.5B-Instruct-GGUF
ARG MODEL_FILE=qwen2.5-0.5b-instruct-q4_k_m.gguf

RUN python -c "from huggingface_hub import hf_hub_download; hf_hub_download('${MODEL_REPO}', '${MODEL_FILE}', local_dir='.', local_dir_use_symlinks=False)"

# Runtime stage
FROM debian:bookworm-slim

RUN apt-get update && apt-get install -y \
    ca-certificates \
    libssl3 \
    curl \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

COPY --from=builder /app/target/release/shimmy /usr/local/bin/shimmy

# Copy downloaded GGUF model
COPY --from=model-downloader /models/*.gguf /app/models/

EXPOSE 11435

# Bind to 0.0.0.0:11435 for container networking
CMD ["shimmy", "serve", "--bind", "0.0.0.0:11435"]
